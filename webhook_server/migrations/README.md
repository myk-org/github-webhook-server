# Database Migrations

This directory contains Alembic database migrations for the GitHub Webhook Server metrics feature.

## Overview

Alembic manages database schema changes through versioned migration scripts. Each migration represents a specific change to the database schema and can be applied (`upgrade`) or reverted (`downgrade`).

## Prerequisites

- PostgreSQL database configured in `config.yaml` (metrics-database section)
- Metrics dependencies installed: `uv sync --extra metrics --extra ai` or `uv add asyncpg alembic sqlalchemy[asyncio]`
- Database connection verified (see DatabaseManager health check)

## Configuration

Database configuration is loaded from `config.yaml`:

```yaml
metrics-database:
  host: localhost
  port: 5432
  database: webhook_metrics
  username: webhook_user
  password: <DATABASE_PASSWORD>
  pool-size: 20
```

**IMPORTANT:** Alembic loads database configuration from `config.yaml` (NOT from `alembic.ini`). The database URL is constructed dynamically in `env.py`.

## Migration Workflow

### Creating Migrations

#### Autogenerate Migration (Recommended)

Automatically detect schema changes by comparing SQLAlchemy models to database:

```bash
# Create migration with auto-detected changes
uv run alembic revision --autogenerate -m "add webhook_events table"

# Review generated migration in webhook_server/migrations/versions/
# Edit if needed to customize upgrade/downgrade logic
```

#### Manual Migration

Create empty migration template for custom changes:

```bash
# Create empty migration
uv run alembic revision -m "add custom indexes"

# Edit the generated file in webhook_server/migrations/versions/
# Add your upgrade() and downgrade() logic
```

### Applying Migrations

```bash
# Upgrade to latest version (head)
uv run alembic upgrade head

# Upgrade by 1 version
uv run alembic upgrade +1

# Upgrade to specific revision
uv run alembic upgrade abc123def456
```

### Reverting Migrations

```bash
# Downgrade by 1 version
uv run alembic downgrade -1

# Downgrade to specific revision
uv run alembic downgrade abc123def456

# Downgrade all migrations (WARNING: destructive!)
uv run alembic downgrade base
```

### Migration Information

```bash
# Show current database version
uv run alembic current

# Show migration history
uv run alembic history

# Show detailed migration history
uv run alembic history --verbose

# Show specific migration details
uv run alembic show abc123def456
```

### Offline Migrations (SQL Scripts)

Generate SQL scripts without database connection:

```bash
# Generate SQL for all pending migrations
uv run alembic upgrade head --sql > migration.sql

# Generate SQL for specific migration
uv run alembic upgrade abc123def456 --sql > migration_abc123.sql

# Review SQL and apply manually to database
psql -h localhost -U webhook_user -d webhook_metrics -f migration.sql
```

## Migration File Naming

Migration files use timestamp-based naming for better organization:

```text
Format: YYYYMMDD_HHMM_<revision>_<slug>.py
Example: 20250123_1430_abc123def456_add_webhook_events_table.py
```

This format:
- Sorts chronologically in directory listings
- Shows creation time at a glance
- Includes descriptive slug for quick identification

## Best Practices

### Writing Migrations

1. **Review autogenerated migrations** - Alembic detection isn't perfect
2. **Test upgrades AND downgrades** - Always verify both directions work
3. **Use transactions** - Alembic wraps migrations in transactions by default
4. **Add indexes carefully** - Create indexes `CONCURRENTLY` in production
5. **Handle data migrations** - Separate schema and data changes when possible

### Migration Content

```python
def upgrade() -> None:
    """Apply migration changes to database schema."""
    # Create table
    op.create_table(
        'webhook_events',
        sa.Column('id', sa.Integer(), nullable=False),
        sa.Column('event_type', sa.String(length=50), nullable=False),
        sa.Column('timestamp', sa.DateTime(), nullable=False),
        sa.PrimaryKeyConstraint('id')
    )

    # Create index (use CONCURRENTLY in production)
    # op.create_index('ix_webhook_events_timestamp', 'webhook_events', ['timestamp'])


def downgrade() -> None:
    """Revert migration changes from database schema."""
    # Drop in reverse order
    # op.drop_index('ix_webhook_events_timestamp', table_name='webhook_events')
    op.drop_table('webhook_events')
```

### Production Migrations

1. **Backup database** before applying migrations
2. **Test in staging** environment first
3. **Review generated SQL** with `--sql` flag
4. **Use transactions** - default behavior, but verify
5. **Monitor performance** - large migrations can lock tables
6. **Create indexes concurrently** - use `postgresql_concurrently=True`

### Handling Failures

If migration fails:

```bash
# Check current database version
uv run alembic current

# Check what went wrong in database
psql -h localhost -U webhook_user -d webhook_metrics
SELECT * FROM alembic_version;

# If partially applied, manually fix database or revert
# Then update alembic_version table to correct state
```

## Integration with Webhook Server

### Startup Migrations (Optional)

To automatically apply migrations on server startup, add to your startup script:

```python
import subprocess

# Apply pending migrations
result = subprocess.run(["uv", "run", "alembic", "upgrade", "head"], check=True)
```

**WARNING:** Automatic migrations are NOT recommended in production. Always apply migrations manually with proper monitoring and backup.

### Health Checks

Use `DatabaseManager.health_check()` to verify database connectivity:

```python
from webhook_server.libs.database import get_database_manager

async def check_database():
    db_manager = get_database_manager()
    async with db_manager as db:
        is_healthy = await db.health_check()
        if not is_healthy:
            raise RuntimeError("Database health check failed")
```

## Common Issues

### Issue: "Target database is not up to date"

**Cause:** Database schema doesn't match migrations

```bash
# Check current version
uv run alembic current

# Check pending migrations
uv run alembic history

# Apply pending migrations
uv run alembic upgrade head
```

### Issue: "Can't locate revision abc123"

**Cause:** Migration file missing or revision ID mismatch

```bash
# Verify migration files exist
ls -la webhook_server/migrations/versions/

# Check migration history
uv run alembic history

# If migration file deleted, recreate or revert to known good state
```

### Issue: "FAILED: Can't acquire lock"

**Cause:** Database table locked by another process

```bash
# Check for active connections
psql -h localhost -U webhook_user -d webhook_metrics
SELECT * FROM pg_stat_activity WHERE datname = 'webhook_metrics';

# Terminate blocking connections (if safe)
SELECT pg_terminate_backend(pid) FROM pg_stat_activity WHERE datname = 'webhook_metrics' AND pid != pg_backend_pid();
```

### Issue: "Config file not found"

**Cause:** `config.yaml` not found in `WEBHOOK_SERVER_DATA_DIR`

```bash
# Check environment variable
echo $WEBHOOK_SERVER_DATA_DIR

# Set environment variable if not set
export WEBHOOK_SERVER_DATA_DIR=/home/podman/data

# Verify config file exists
ls -la $WEBHOOK_SERVER_DATA_DIR/config.yaml
```

## Architecture Notes

### Async Support

This migration setup uses **async PostgreSQL** via `asyncpg`:

- Migrations run in async context (`run_async_migrations()`)
- Uses `async_engine_from_config()` for engine creation
- Connection handling via `connection.run_sync()`

### Configuration Loading

Database configuration and migration paths are loaded dynamically from `config.yaml` (NOT `alembic.ini`):

1. `env.py` imports `webhook_server.libs.config.Config`
2. Reads `metrics-database` section from `config.yaml`
3. Constructs PostgreSQL URL: `postgresql+asyncpg://user:pass@host:port/db`  # pragma: allowlist secret
4. Sets `sqlalchemy.url` in Alembic config dynamically
5. Sets `version_locations` based on `WEBHOOK_SERVER_DATA_DIR` environment variable

**Migration Versions Path:**
- The path where Alembic stores migration version files is determined by `WEBHOOK_SERVER_DATA_DIR`
- Default path: `{WEBHOOK_SERVER_DATA_DIR}/migrations/versions`
- Container default: `/home/podman/data/migrations/versions`
- Non-container example: `/home/myakove/data/migrations/versions` (when `WEBHOOK_SERVER_DATA_DIR=/home/myakove/data`)
- This supports both container and non-container deployments without hardcoded paths

### Model Discovery

SQLAlchemy models are imported in `env.py` for autogenerate support:

```python
from webhook_server.libs.models import Base
target_metadata = Base.metadata
```

This enables Alembic to auto-detect schema changes by comparing SQLAlchemy models to the database.

## Next Steps

1. **Create SQLAlchemy models** (task #5) - Define webhook_events, pull_request_metrics, etc.
2. **Generate initial migration** - `uv run alembic revision --autogenerate -m "initial schema"`
3. **Apply migration** - `uv run alembic upgrade head`
4. **Verify schema** - Check database tables created correctly

## Resources

- [Alembic Documentation](https://alembic.sqlalchemy.org/)
- [SQLAlchemy Async Documentation](https://docs.sqlalchemy.org/en/20/orm/extensions/asyncio.html)
- [asyncpg Documentation](https://magicstack.github.io/asyncpg/)
- Project: `webhook_server/libs/database.py` - DatabaseManager implementation
- Project: `examples/config.yaml` - Database configuration examples
